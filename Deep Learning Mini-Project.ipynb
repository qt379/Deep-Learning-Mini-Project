{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxI8mx7eXdOA"
      },
      "source": [
        "# 1.Import related modules"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/My Drive/Colab Notebooks/resnet_cifar10"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-25T05:56:26.986436Z",
          "iopub.execute_input": "2022-08-25T05:56:26.986769Z",
          "iopub.status.idle": "2022-08-25T05:56:26.991068Z",
          "shell.execute_reply.started": "2022-08-25T05:56:26.986737Z",
          "shell.execute_reply": "2022-08-25T05:56:26.990038Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNXl03Qsulv6",
        "outputId": "50eb5dd6-2dcd-4640-bea3-d7111057eeb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/Colab Notebooks/resnet_cifar10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import tarfile\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets.utils import download_url\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as tt\n",
        "from torch.utils.data import random_split\n",
        "from torchvision.utils import make_grid\n",
        "import matplotlib.pyplot as plt\n",
        "import d2lzh_pytorch as d2l\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "KpQyex6aZIps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pHJMjZ6XdOB"
      },
      "source": [
        "# 2.Obtain the data set and do preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing the Data\n"
      ],
      "metadata": {
        "id": "HR3iFw4wulv7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-25T05:56:28.842529Z",
          "iopub.execute_input": "2022-08-25T05:56:28.843014Z",
          "iopub.status.idle": "2022-08-25T05:56:28.850427Z",
          "shell.execute_reply.started": "2022-08-25T05:56:28.842955Z",
          "shell.execute_reply": "2022-08-25T05:56:28.849272Z"
        },
        "trusted": true,
        "id": "kd0TaMTyulv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir('cifar10/cifar10')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-25T05:56:29.039088Z",
          "iopub.execute_input": "2022-08-25T05:56:29.039596Z",
          "iopub.status.idle": "2022-08-25T05:56:29.065428Z",
          "shell.execute_reply.started": "2022-08-25T05:56:29.039546Z",
          "shell.execute_reply": "2022-08-25T05:56:29.064512Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M09nigvHulv8",
        "outputId": "d537f95a-6083-4831-921b-a1c473322033"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['test', 'labels.txt', 'train']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data_dir = 'cifar10/cifar10'\n",
        "print(os.listdir(data_dir))\n",
        "classes = os.listdir(data_dir + \"/train\")\n",
        "print(classes)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-25T05:56:29.303721Z",
          "iopub.execute_input": "2022-08-25T05:56:29.306247Z",
          "iopub.status.idle": "2022-08-25T05:56:29.322940Z",
          "shell.execute_reply.started": "2022-08-25T05:56:29.306201Z",
          "shell.execute_reply": "2022-08-25T05:56:29.322175Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5y61G5wulv8",
        "outputId": "ec9289e6-95fd-458d-e5dd-056b2f95a1c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['test', 'labels.txt', 'train']\n",
            "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data transforms (normalization & data augmentation)\n",
        "stats = ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "train_tfms = tt.Compose([tt.RandomCrop(32, padding=4, padding_mode='reflect'),\n",
        "                         tt.RandomHorizontalFlip(),\n",
        "                         tt.ToTensor(),\n",
        "                         tt.Normalize(*stats,inplace=True)])\n",
        "valid_tfms = tt.Compose([tt.ToTensor(), tt.Normalize(*stats)])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-25T05:56:30.199680Z",
          "iopub.execute_input": "2022-08-25T05:56:30.200015Z",
          "iopub.status.idle": "2022-08-25T05:56:30.206426Z",
          "shell.execute_reply.started": "2022-08-25T05:56:30.199983Z",
          "shell.execute_reply": "2022-08-25T05:56:30.205433Z"
        },
        "trusted": true,
        "id": "TBlSktfkulv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch datasets\n",
        "cifar10_train  = ImageFolder(data_dir+'/train', train_tfms)\n",
        "cifar10_test = ImageFolder(data_dir+'/test', valid_tfms)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-25T05:56:33.118872Z",
          "iopub.execute_input": "2022-08-25T05:56:33.119511Z",
          "iopub.status.idle": "2022-08-25T05:57:39.055906Z",
          "shell.execute_reply.started": "2022-08-25T05:56:33.119464Z",
          "shell.execute_reply": "2022-08-25T05:57:39.055062Z"
        },
        "trusted": true,
        "id": "3PRwAdEgulv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m79NwRN9XdOB"
      },
      "source": [
        "\n",
        "Preprocessing and transforming images can improve model accuracy and convergence speed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qm2ZnNrZXdOC",
        "outputId": "13e19099-a683-4a67-9525-387667276595"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'torchvision.datasets.cifar.CIFAR10'>\n",
            "50000 10000\n"
          ]
        }
      ],
      "source": [
        "# Print the data type of the training dataset\n",
        "print(type(cifar10_train))\n",
        "\n",
        "# Print the number of images in the training and test datasets\n",
        "print(len(cifar10_train), len(cifar10_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVoF2w-sXdOC",
        "outputId": "70a07f06-d44a-4a56-c951-2f067b805412"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([3, 32, 32]) torch.float32\n",
            "4\n"
          ]
        }
      ],
      "source": [
        "# Retrieve a sample from the training dataset (the fourth image)\n",
        "feature, label = cifar10_train[3]\n",
        "\n",
        "# Print the dimensions and data type of the image\n",
        "print(feature.shape, feature.dtype)\n",
        "\n",
        "# Print the label associated with the image\n",
        "print(label)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YP1tDbMoXdOC",
        "outputId": "d001500e-5c48-45d3-f725-574978581977"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
          ]
        }
      ],
      "source": [
        "def get_labels(numeric_labels):\n",
        "    # List of human-readable labels for CIFAR-10 categories\n",
        "    text_labels = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "                   'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "    # Map each numeric label to its corresponding text label\n",
        "    return [text_labels[int(label)] for label in numeric_labels]\n",
        "\n",
        "print(get_labels([0,1,2,3,4,5,6,7,8,9]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4Ul0aZwXdOC"
      },
      "source": [
        "# 3. Define ResNet18 model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SWfHis3dXdOC"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        # Adjust shortcut to match dimension changes caused by convolutions\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != self.expansion * out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, self.expansion * out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion * out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))  # Activation after first convolution\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)               # Add output of shortcut to main path\n",
        "        out = F.relu(out)                     # Final activation after addition\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pz8P0jizXdOC"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_channels = 64  # Initial number of channels\n",
        "\n",
        "        # Initial convolution and batch normalization\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "\n",
        "        # Create each ResNet layer with varying number of blocks\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "\n",
        "        # Fully connected layer for classification\n",
        "        self.linear = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "    # Helper function to create layers of blocks\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_channels, planes, stride))\n",
        "            self.in_channels = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    # Forward propagation function\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))  # Activation after initial convolution\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)  # Average pooling\n",
        "        out = out.view(out.size(0), -1)  # Flatten\n",
        "        out = self.linear(out)  # Fully connected layer\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3q0MsdCXdOD",
        "outputId": "07b117a4-1c48-4824-ce42-ba55213caff5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Initialize ResNet with BasicBlock and 2 blocks in each of its 4 layers\n",
        "net = ResNet(BasicBlock, [2, 2, 2, 2])\n",
        "\n",
        "print(net)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQhmwrYeXdOD"
      },
      "source": [
        "# 4. Training model preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8EiYl02XdOD"
      },
      "outputs": [],
      "source": [
        "# Set batch size for training\n",
        "batch_size = 128\n",
        "\n",
        "# Initialize data loaders for training and testing\n",
        "train_iter = torch.utils.data.DataLoader(cifar10_train, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "test_iter = torch.utils.data.DataLoader(cifar10_test, batch_size=100, shuffle=False, num_workers=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLN3TgbMXdOD"
      },
      "outputs": [],
      "source": [
        "# Enable multi-GPU training if CUDA is available\n",
        "if device == 'cuda':\n",
        "    net = torch.nn.DataParallel(net)\n",
        "    cudnn.benchmark = True\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5hQ1iBNXdOD"
      },
      "source": [
        "An accuracy evaluation function is created, which is mainly used to input the network model obtained in each round into the test set data during the training process to obtain its generalization accuracy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RH1cj02jXdOD"
      },
      "outputs": [],
      "source": [
        "# Evaluate model accuracy on a dataset\n",
        "import torch\n",
        "\n",
        "def calculate_accuracy(data_loader, model, device=None):\n",
        "    if device is None and isinstance(model, torch.nn.Module):\n",
        "        device = next(model.parameters()).device\n",
        "\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in data_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            model.eval()\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct_predictions += (predicted == labels).sum().item()\n",
        "            model.train()\n",
        "\n",
        "            total_samples += labels.size(0)\n",
        "\n",
        "    return correct_predictions / total_samples\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7_x9nBRXdOE"
      },
      "source": [
        "\n",
        "Created a training function, mainly used for loop training, and after each round of training, print the training set accuracy and test set accuracy of this round and other training information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0opfRLuXdOE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import time\n",
        "\n",
        "def train(model, train_loader, test_loader, batch_size, optimizer, device, num_epochs):\n",
        "    model = model.to(device)\n",
        "    print(\"Training on\", device)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    batch_count = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss_sum, train_acc_sum, n, start_time = 0.0, 0.0, 0, time.time()\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss_sum += loss.item()\n",
        "            train_acc_sum += (outputs.argmax(dim=1) == labels).sum().item()\n",
        "            n += labels.size(0)\n",
        "            batch_count += 1\n",
        "\n",
        "        test_acc = calculate_accuracy(test_loader, model, device)\n",
        "        print('Epoch %d, Loss: %.4f, Train Acc: %.3f, Test Acc: %.3f, Time: %.1f sec'\n",
        "              % (epoch + 1, train_loss_sum / batch_count, train_acc_sum / n, test_acc, time.time() - start_time))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMJ0Bi5WXdOE"
      },
      "source": [
        "# 5.Training model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set learning rate and number of epochs\n",
        "lr, num_epochs = 0.01, 50\n",
        "# Initialize the optimizer\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "# Start training the model\n",
        "train(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26ueVDgidx4F",
        "outputId": "adc1f39c-fa6c-496c-bf96-bcb9a01fdf9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training on cuda\n",
            "epoch 1, loss 1.8015, train acc 0.335, test acc 0.419, time 391.6 sec\n",
            "epoch 2, loss 0.6479, train acc 0.530, test acc 0.599, time 382.3 sec\n",
            "epoch 3, loss 0.3319, train acc 0.638, test acc 0.661, time 381.4 sec\n",
            "epoch 4, loss 0.2107, train acc 0.705, test acc 0.732, time 381.9 sec\n",
            "epoch 5, loss 0.1421, train acc 0.753, test acc 0.753, time 383.0 sec\n",
            "epoch 6, loss 0.1010, train acc 0.790, test acc 0.780, time 383.1 sec\n",
            "epoch 7, loss 0.0753, train acc 0.817, test acc 0.804, time 381.5 sec\n",
            "epoch 8, loss 0.0582, train acc 0.839, test acc 0.824, time 381.4 sec\n",
            "epoch 9, loss 0.0473, train acc 0.853, test acc 0.842, time 381.7 sec\n",
            "epoch 10, loss 0.0390, train acc 0.865, test acc 0.837, time 381.8 sec\n",
            "epoch 11, loss 0.0325, train acc 0.879, test acc 0.857, time 382.8 sec\n",
            "epoch 12, loss 0.0275, train acc 0.885, test acc 0.846, time 382.0 sec\n",
            "epoch 13, loss 0.0240, train acc 0.894, test acc 0.850, time 382.8 sec\n",
            "epoch 14, loss 0.0208, train acc 0.901, test acc 0.865, time 381.7 sec\n",
            "epoch 15, loss 0.0182, train acc 0.908, test acc 0.861, time 381.9 sec\n",
            "epoch 16, loss 0.0159, train acc 0.914, test acc 0.885, time 382.0 sec\n",
            "epoch 17, loss 0.0142, train acc 0.919, test acc 0.873, time 385.2 sec\n",
            "epoch 18, loss 0.0126, train acc 0.925, test acc 0.877, time 381.8 sec\n",
            "epoch 19, loss 0.0114, train acc 0.929, test acc 0.882, time 381.5 sec\n",
            "epoch 20, loss 0.0102, train acc 0.933, test acc 0.883, time 382.3 sec\n",
            "epoch 21, loss 0.0092, train acc 0.938, test acc 0.893, time 381.5 sec\n",
            "epoch 22, loss 0.0084, train acc 0.941, test acc 0.892, time 382.3 sec\n",
            "epoch 23, loss 0.0075, train acc 0.945, test acc 0.890, time 383.9 sec\n",
            "epoch 24, loss 0.0069, train acc 0.948, test acc 0.894, time 386.1 sec\n",
            "epoch 25, loss 0.0065, train acc 0.949, test acc 0.891, time 384.3 sec\n",
            "epoch 26, loss 0.0060, train acc 0.953, test acc 0.886, time 382.2 sec\n",
            "epoch 27, loss 0.0056, train acc 0.955, test acc 0.901, time 381.9 sec\n",
            "epoch 28, loss 0.0051, train acc 0.956, test acc 0.879, time 381.7 sec\n",
            "epoch 29, loss 0.0050, train acc 0.958, test acc 0.898, time 382.7 sec\n",
            "epoch 30, loss 0.0045, train acc 0.961, test acc 0.900, time 381.6 sec\n",
            "epoch 31, loss 0.0042, train acc 0.965, test acc 0.903, time 381.6 sec\n",
            "epoch 32, loss 0.0040, train acc 0.963, test acc 0.894, time 381.8 sec\n",
            "epoch 33, loss 0.0038, train acc 0.966, test acc 0.898, time 381.6 sec\n",
            "epoch 34, loss 0.0037, train acc 0.966, test acc 0.890, time 381.0 sec\n",
            "epoch 35, loss 0.0035, train acc 0.968, test acc 0.905, time 381.5 sec\n",
            "epoch 36, loss 0.0032, train acc 0.971, test acc 0.903, time 381.2 sec\n",
            "epoch 37, loss 0.0031, train acc 0.970, test acc 0.906, time 380.9 sec\n",
            "epoch 38, loss 0.0030, train acc 0.971, test acc 0.909, time 380.6 sec\n",
            "epoch 39, loss 0.0029, train acc 0.972, test acc 0.905, time 381.1 sec\n",
            "epoch 40, loss 0.0028, train acc 0.973, test acc 0.904, time 381.0 sec\n",
            "epoch 41, loss 0.0028, train acc 0.971, test acc 0.909, time 381.0 sec\n",
            "epoch 42, loss 0.0026, train acc 0.976, test acc 0.902, time 382.4 sec\n",
            "epoch 43, loss 0.0024, train acc 0.977, test acc 0.891, time 380.8 sec\n",
            "epoch 44, loss 0.0025, train acc 0.976, test acc 0.899, time 380.8 sec\n",
            "epoch 45, loss 0.0024, train acc 0.977, test acc 0.905, time 380.8 sec\n",
            "epoch 46, loss 0.0024, train acc 0.976, test acc 0.905, time 380.8 sec\n",
            "epoch 47, loss 0.0022, train acc 0.979, test acc 0.901, time 380.9 sec\n",
            "epoch 48, loss 0.0021, train acc 0.980, test acc 0.909, time 381.3 sec\n",
            "epoch 49, loss 0.0021, train acc 0.979, test acc 0.899, time 381.1 sec\n",
            "epoch 50, loss 0.0021, train acc 0.979, test acc 0.902, time 381.1 sec\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}